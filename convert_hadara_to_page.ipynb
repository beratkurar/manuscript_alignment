{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code converts hadara format xml files to page format xml files. It does not contain text line information. It only contains word bounding boxes and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from lxml import etree as ET\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from bidi.algorithm import get_display\n",
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_bboxes_and_labels_from_hadara_xml(hadara_xml_path, image_root_name):\n",
    "    tree = ET.parse(hadara_xml_path)\n",
    "    root = tree.getroot()\n",
    "    word_bboxes = []\n",
    "    word_labels = []\n",
    "    for element in root.findall('DocumentElement'):\n",
    "        transcript = element.find('Transcript')\n",
    "        if (transcript!=None):\n",
    "            word_label = transcript.text\n",
    "            x = int(element.find('X').text)\n",
    "            y = int(element.find('Y').text)\n",
    "            h = int(element.find('Height').text)\n",
    "            w = int(element.find('Width').text)\n",
    "            word_bbox = (x,y,w,h)\n",
    "            if (word_bboxes!=None):\n",
    "                word_bboxes.append(word_bbox)\n",
    "                word_labels.append(word_label)\n",
    "    print('Gathered '+ str(len(word_labels)) + ' words on ' +image_name)\n",
    "    return word_bboxes, word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates(cnt):\n",
    "    coords= str(cnt[0])+','+str(cnt[1])+' '+str(cnt[0]+cnt[2])+','+str(cnt[1])+' '+str(cnt[0]+cnt[2])+','+str(cnt[1]+cnt[3])+' '+str(cnt[0])+','+str(cnt[1]+cnt[3])\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_bboxes_and_labels_to_page_xml(word_bboxes, word_labels, image_path, image_name, xml_folder_path):\n",
    "    xmlns = \"http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15\"\n",
    "    xsi =\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "    schemaLocation = \"http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15 http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15/pagecontent.xsd\"\n",
    "    PcGts = ET.Element(\"{\" + xmlns + \"}PcGts\",\n",
    "                           attrib={\"{\" + xsi + \"}schemaLocation\" : schemaLocation}, \n",
    "                            nsmap={'xsi': xsi, None: xmlns})\n",
    "    PcGts.set(\"pcGtsId\",\"pc-aletheiaexamplepage\")\n",
    "    Metadata = ET.SubElement(PcGts, 'Metadata')\n",
    "    Creator = ET.SubElement(Metadata, 'Creator')\n",
    "    Creator.text='PRImA Research Lab'\n",
    "    Metadata.append(Creator)\n",
    "    Created = ET.SubElement(Metadata, 'Created')\n",
    "    Created.text='2015-07-17T15:27:13' \n",
    "    Metadata.append(Created)\n",
    "    LastChange = ET.SubElement(Metadata, 'LastChange')\n",
    "    LastChange.text='2017-07-14T10:03:33' \n",
    "    Metadata.append(LastChange)\n",
    "    Comments = ET.SubElement(Metadata, 'Comments')\n",
    "    Comments.text='Example Page' \n",
    "    Metadata.append(Comments)\n",
    "    PcGts.append(Metadata)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    rows,cols,_=img.shape\n",
    "    Page=ET.SubElement(PcGts,'Page')\n",
    "    Page.set('imageFilename',image_name) \n",
    "    Page.set('imageWidth',str(cols))\n",
    "    Page.set('imageHeight',str(rows))\n",
    "    \n",
    "    textregionid=0\n",
    "    coords= '1,1 '+str(cols-2)+',1 '+str(cols-2)+','+str(rows-2)+' 1,'+str(rows-2)\n",
    "    TextRegion = ET.SubElement(Page, 'TextRegion')   \n",
    "    TextRegion.set('id','r'+str(textregionid))\n",
    "    TextRegion.set('type','paragraph')\n",
    "    Page.append(TextRegion)\n",
    "    Coords = ET.SubElement(TextRegion, 'Coords')        \n",
    "    Coords.set('points',coords)\n",
    "    TextRegion.append(Coords)\n",
    "    \n",
    "    TextLine = ET.SubElement(TextRegion, 'TextLine')   \n",
    "    TextLine.set('id','l0')\n",
    "    TextRegion.append(TextLine)\n",
    "\n",
    "    Coords = ET.SubElement(TextLine, 'Coords')        \n",
    "    Coords.set('points',coords)\n",
    "    TextLine.append(Coords)\n",
    "    \n",
    "    wordid = 0\n",
    "    for word_bbox in word_bboxes:\n",
    "        wcoords = coordinates(word_bbox)\n",
    "        Word = ET.SubElement(TextLine, 'Word')\n",
    "        Word.set('id','w'+str(wordid))\n",
    "        Coords = ET.SubElement(Word, 'Coords')        \n",
    "        Coords.set('points',wcoords)\n",
    "        TextEquiv = ET.SubElement(Word, 'TextEquiv')\n",
    "        UnicodeTextEquiv = ET.SubElement(TextEquiv, 'Unicode')\n",
    "        UnicodeTextEquiv.text = word_labels[wordid]\n",
    "        TextEquiv.append(UnicodeTextEquiv)\n",
    "        Word.append(TextEquiv)\n",
    "        TextLine.append(Word)\n",
    "        wordid = wordid + 1\n",
    "    \n",
    "    mydata = ET.tostring(PcGts,pretty_print=True, encoding='utf-8', xml_declaration=True)    \n",
    "    image_root_name = image_name[:-4]\n",
    "    myfile = open(xml_folder_path+'/'+image_root_name+'.xml', \"wb\")  \n",
    "    myfile.write(mydata) \n",
    "    myfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_images_dir = 'book2_color_images/'\n",
    "hadara_xmls_dir = 'book2_hadara_xmls/'\n",
    "words_page_xmls_dir = 'book2_words_page_xmls/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003-2.png\n",
      "book2_hadara_xmls/003-2.xml\n",
      "Gathered 639 words on 003-2.png\n",
      "Started to generate pagexml for 003-2.png\n",
      "004-1.png\n",
      "book2_hadara_xmls/004-1.xml\n",
      "Gathered 576 words on 004-1.png\n",
      "Started to generate pagexml for 004-1.png\n",
      "004-2.png\n",
      "book2_hadara_xmls/004-2.xml\n",
      "Gathered 686 words on 004-2.png\n",
      "Started to generate pagexml for 004-2.png\n",
      "005-1.png\n",
      "book2_hadara_xmls/005-1.xml\n",
      "Gathered 731 words on 005-1.png\n",
      "Started to generate pagexml for 005-1.png\n",
      "005-2.png\n",
      "book2_hadara_xmls/005-2.xml\n",
      "Gathered 745 words on 005-2.png\n",
      "Started to generate pagexml for 005-2.png\n",
      "006-1.png\n",
      "book2_hadara_xmls/006-1.xml\n",
      "Gathered 749 words on 006-1.png\n",
      "Started to generate pagexml for 006-1.png\n",
      "006-2.png\n",
      "book2_hadara_xmls/006-2.xml\n",
      "Gathered 694 words on 006-2.png\n",
      "Started to generate pagexml for 006-2.png\n",
      "007-1.png\n",
      "book2_hadara_xmls/007-1.xml\n",
      "Gathered 722 words on 007-1.png\n",
      "Started to generate pagexml for 007-1.png\n",
      "007-2.png\n",
      "book2_hadara_xmls/007-2.xml\n",
      "Gathered 719 words on 007-2.png\n",
      "Started to generate pagexml for 007-2.png\n",
      "008-1.png\n",
      "book2_hadara_xmls/008-1.xml\n",
      "Gathered 701 words on 008-1.png\n",
      "Started to generate pagexml for 008-1.png\n",
      "003-1.png\n",
      "book2_hadara_xmls/003-1.xml\n",
      "Gathered 343 words on 003-1.png\n",
      "Started to generate pagexml for 003-1.png\n",
      "All the pages have been processed.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(words_page_xmls_dir):\n",
    "    shutil.rmtree(words_page_xmls_dir)\n",
    "os.mkdir(words_page_xmls_dir)\n",
    "\n",
    "c=0\n",
    "for image_name in os.listdir(color_images_dir):\n",
    "    print(image_name)\n",
    "    image_root_name = image_name[:-4]\n",
    "    hadara_xml_path = hadara_xmls_dir + image_root_name + '.xml'\n",
    "    print(hadara_xml_path)\n",
    "      \n",
    "    word_bboxes, word_labels = word_bboxes_and_labels_from_hadara_xml(hadara_xml_path, image_root_name)\n",
    "    \n",
    "    print ('Started to generate pagexml for '+ image_name)\n",
    "    image_path = color_images_dir + '/' + image_name\n",
    "    word_bboxes_and_labels_to_page_xml(word_bboxes, word_labels, image_path, image_name, words_page_xmls_dir)\n",
    "\n",
    "print ('All the pages have been processed.')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
