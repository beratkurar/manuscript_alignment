{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code converts hadara format xml files to page format xml files. It contains the word bounding boxes and their labels. It extracts text line bounding boxes from the word bounding boxes. It contains these text line bounding boxes and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from lxml import etree as ET\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from bidi.algorithm import get_display\n",
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates(cnt):\n",
    "    coords= str(cnt[0])+','+str(cnt[1])+' '+str(cnt[0]+cnt[2])+','+str(cnt[1])+' '+str(cnt[0]+cnt[2])+','+str(cnt[1]+cnt[3])+' '+str(cnt[0])+','+str(cnt[1]+cnt[3])\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_height(h):\n",
    "    if h <= 35:\n",
    "        reduced_h = 10\n",
    "    else:\n",
    "        reduced_h = h - 30\n",
    "    return reduced_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_label(labelList):\n",
    "    line_label=''\n",
    "    for label in labelList:\n",
    "        line_label=line_label+' '+label\n",
    "    return line_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_box(rectList):\n",
    "    arr = []\n",
    "    for rect in rectList:\n",
    "        arr.append((rect[0],rect[1]))\n",
    "        arr.append((rect[0]+rect[2],rect[1]+rect[3]))\n",
    "    (x,y,w,h) = cv2.boundingRect(np.asarray(arr))\n",
    "    return x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_bboxes_and_labels_from_hadara_xml(hadara_xml_path, image_root_name):\n",
    "    tree = ET.parse(hadara_xml_path)\n",
    "    root = tree.getroot()\n",
    "    word_bboxes = []\n",
    "    word_labels = []\n",
    "    for element in root.findall('DocumentElement'):\n",
    "        transcript = element.find('Transcript')\n",
    "        if (transcript!=None):\n",
    "            word_label = transcript.text\n",
    "            x = int(element.find('X').text)\n",
    "            y = int(element.find('Y').text)\n",
    "            h = int(element.find('Height').text)\n",
    "            w = int(element.find('Width').text)\n",
    "            word_bbox = (x,y,w,h)\n",
    "            if (word_bboxes!=None):\n",
    "                word_bboxes.append(word_bbox)\n",
    "                word_labels.append(word_label)\n",
    "    print('Gathered '+ str(len(word_labels)) + ' words on ' +image_name)\n",
    "    return word_bboxes, word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_from_words(word_bboxes, word_labels):\n",
    "    line_bboxes = []\n",
    "    line_labels = []\n",
    "    sorted_word_bboxes = []\n",
    "    sorted_word_labels = []\n",
    "    # Sort by y coordinate\n",
    "    word_bboxes, word_labels = zip(*sorted(zip(word_bboxes, word_labels), key=lambda p: p[0][1]))\n",
    "    word_bboxes = list(word_bboxes)\n",
    "    word_labels = list(word_labels)\n",
    "    # Bottom of the first rectangle is the baseline\n",
    "    reduced_h = reduce_height(word_bboxes[0][3])\n",
    "    baseline = word_bboxes[0][1] + reduced_h - 1\n",
    "    end_idx = 0\n",
    "    for i in range(len(word_bboxes)):\n",
    "        # Continue iterating until the box whose y coordinate is below the current baseline\n",
    "        if word_bboxes[i][1] > baseline:\n",
    "            # Sort the boxes whose y coordinates are above the current baseline, by their x coordinate, in descending order\n",
    "            word_bboxes[end_idx:i], word_labels[end_idx:i] = zip(*sorted(zip(word_bboxes[end_idx:i], word_labels[end_idx:i]), reverse=True, key=lambda p: p[0][0]))\n",
    "\n",
    "            if len(word_bboxes[end_idx:i])>0:\n",
    "                line_bbox = one_box(word_bboxes[end_idx:i])\n",
    "                line_bboxes.append(line_bbox)\n",
    "                line_label = one_label(word_labels[end_idx:i])\n",
    "                line_labels.append(line_label)\n",
    "                sorted_word_bboxes.append(word_bboxes[end_idx:i])\n",
    "                sorted_word_labels.append(word_labels[end_idx:i])\n",
    "\n",
    "            end_idx = i\n",
    "        # Update the baseline. \n",
    "        # New baseline is the bottom of the box whose y coordinate is below the current baseline\n",
    "        reduced_h = reduce_height(word_bboxes[i][3])\n",
    "        baseline = max(word_bboxes[i][1] + reduced_h - 1, baseline)\n",
    "\n",
    "    # Sort the word bboxes at the final line\n",
    "    if len(word_bboxes[end_idx:i])>0:\n",
    "        word_bboxes[end_idx:i], word_labels[end_idx:i] = zip(*sorted(zip(word_bboxes[end_idx:i], word_labels[end_idx:i]), reverse=True, key=lambda p: p[0][0]))\n",
    "        line_bbox = one_box(word_bboxes[end_idx:i])\n",
    "        line_bboxes.append(line_bbox)\n",
    "        line_label = one_label(word_labels[end_idx:i])\n",
    "        line_labels.append(line_label)\n",
    "        sorted_word_bboxes.append(word_bboxes[end_idx:i])\n",
    "        sorted_word_labels.append(word_labels[end_idx:i])\n",
    "        \n",
    "    return sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pagexml(xml_folder_path, image_file_path, sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels):\n",
    "    xmlns = \"http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15\"\n",
    "    xsi =\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "    schemaLocation = \"http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15 http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15/pagecontent.xsd\"\n",
    "\n",
    "    PcGts = ET.Element(\"{\" + xmlns + \"}PcGts\",\n",
    "                           attrib={\"{\" + xsi + \"}schemaLocation\" : schemaLocation}, \n",
    "                            nsmap={'xsi': xsi, None: xmlns})\n",
    "    PcGts.set(\"pcGtsId\",\"pc-aletheiaexamplepage\")\n",
    "    Metadata = ET.SubElement(PcGts, 'Metadata')\n",
    "    Creator = ET.SubElement(Metadata, 'Creator')\n",
    "    Creator.text='PRImA Research Lab'\n",
    "    Metadata.append(Creator)\n",
    "    Created = ET.SubElement(Metadata, 'Created')\n",
    "    Created.text='2015-07-17T15:27:13' \n",
    "    Metadata.append(Created)\n",
    "    LastChange = ET.SubElement(Metadata, 'LastChange')\n",
    "    LastChange.text='2017-07-14T10:03:33' \n",
    "    Metadata.append(LastChange)\n",
    "    Comments = ET.SubElement(Metadata, 'Comments')\n",
    "    Comments.text='Example Page' \n",
    "    Metadata.append(Comments)\n",
    "    PcGts.append(Metadata)\n",
    "\n",
    "    img = cv2.imread(image_file_path)\n",
    "\n",
    "    rows,cols,_=img.shape\n",
    "    Page=ET.SubElement(PcGts,'Page')\n",
    "    Page.set('imageFilename',image_file_path) \n",
    "    Page.set('imageWidth',str(cols))\n",
    "    Page.set('imageHeight',str(rows))\n",
    "    \n",
    "    textregionid=0\n",
    "    coords= '1,1 '+str(cols-2)+',1 '+str(cols-2)+','+str(rows-2)+' 1,'+str(rows-2)\n",
    "    TextRegion = ET.SubElement(Page, 'TextRegion')   \n",
    "    TextRegion.set('id','r'+str(textregionid))\n",
    "    TextRegion.set('type','paragraph')\n",
    "    Page.append(TextRegion)\n",
    "    Coords = ET.SubElement(TextRegion, 'Coords')        \n",
    "    Coords.set('points',coords)\n",
    "    TextRegion.append(Coords)\n",
    "\n",
    "    textlineid = 0\n",
    "    wordid = 0\n",
    "    for line_bbox in line_bboxes:\n",
    "        tcoords = coordinates(line_bbox)\n",
    "        TextLine = ET.SubElement(TextRegion, 'TextLine')   \n",
    "        TextLine.set('id','l'+str(textlineid))\n",
    "        TextRegion.append(TextLine)\n",
    "\n",
    "        Coords = ET.SubElement(TextLine, 'Coords')        \n",
    "        Coords.set('points',tcoords)\n",
    "        TextLine.append(Coords)\n",
    "\n",
    "        textlinewordid = 0\n",
    "        for word_bbox in sorted_word_bboxes[textlineid]:\n",
    "            wcoords = coordinates(word_bbox)\n",
    "            Word = ET.SubElement(TextLine, 'Word')\n",
    "            Word.set('id','w'+str(wordid))\n",
    "            Coords = ET.SubElement(Word, 'Coords')        \n",
    "            Coords.set('points',wcoords)\n",
    "            TextEquiv = ET.SubElement(Word, 'TextEquiv')\n",
    "            UnicodeTextEquiv = ET.SubElement(TextEquiv, 'Unicode')\n",
    "            UnicodeTextEquiv.text = sorted_word_labels[textlineid][textlinewordid]\n",
    "            TextEquiv.append(UnicodeTextEquiv)\n",
    "            Word.append(TextEquiv)\n",
    "            TextLine.append(Word)\n",
    "            textlinewordid = textlinewordid+1\n",
    "            wordid = wordid + 1\n",
    "\n",
    "        TextEquiv = ET.SubElement(TextLine, 'TextEquiv')\n",
    "        UnicodeTextEquiv = ET.SubElement(TextEquiv, 'Unicode')\n",
    "        UnicodeTextEquiv.text = line_labels[textlineid]\n",
    "        TextEquiv.append(UnicodeTextEquiv)\n",
    "        TextLine.append(TextEquiv)\n",
    "\n",
    "        textlineid = textlineid + 1\n",
    "    \n",
    "    \n",
    "    mydata = ET.tostring(PcGts,pretty_print=True, encoding='utf-8', xml_declaration=True)    \n",
    "    image_name = image_file_path.split('/')[1][:-4]\n",
    "    print(xml_folder_path+image_name+'.xml')\n",
    "    myfile = open(xml_folder_path+image_name+'.xml', \"wb\")  \n",
    "    myfile.write(mydata) \n",
    "    myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_images_dir = 'book2_color_images/'\n",
    "hadara_xmls_dir = 'book2_hadara_xmls/'\n",
    "words_lines_page_xmls_dir = 'book2_words_lines_page_xmls/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003-2.png\n",
      "book2_hadara_xmls/003-2.xml\n",
      "Gathered 639 words on 003-2.png\n",
      "Started to generate pagexml for 003-2.png\n",
      "book2_words_lines_page_xmls/003-2.xml\n",
      "004-1.png\n",
      "book2_hadara_xmls/004-1.xml\n",
      "Gathered 576 words on 004-1.png\n",
      "Started to generate pagexml for 004-1.png\n",
      "book2_words_lines_page_xmls/004-1.xml\n",
      "004-2.png\n",
      "book2_hadara_xmls/004-2.xml\n",
      "Gathered 686 words on 004-2.png\n",
      "Started to generate pagexml for 004-2.png\n",
      "book2_words_lines_page_xmls/004-2.xml\n",
      "005-1.png\n",
      "book2_hadara_xmls/005-1.xml\n",
      "Gathered 731 words on 005-1.png\n",
      "Started to generate pagexml for 005-1.png\n",
      "book2_words_lines_page_xmls/005-1.xml\n",
      "005-2.png\n",
      "book2_hadara_xmls/005-2.xml\n",
      "Gathered 745 words on 005-2.png\n",
      "Started to generate pagexml for 005-2.png\n",
      "book2_words_lines_page_xmls/005-2.xml\n",
      "006-1.png\n",
      "book2_hadara_xmls/006-1.xml\n",
      "Gathered 749 words on 006-1.png\n",
      "Started to generate pagexml for 006-1.png\n",
      "book2_words_lines_page_xmls/006-1.xml\n",
      "006-2.png\n",
      "book2_hadara_xmls/006-2.xml\n",
      "Gathered 694 words on 006-2.png\n",
      "Started to generate pagexml for 006-2.png\n",
      "book2_words_lines_page_xmls/006-2.xml\n",
      "007-1.png\n",
      "book2_hadara_xmls/007-1.xml\n",
      "Gathered 722 words on 007-1.png\n",
      "Started to generate pagexml for 007-1.png\n",
      "book2_words_lines_page_xmls/007-1.xml\n",
      "007-2.png\n",
      "book2_hadara_xmls/007-2.xml\n",
      "Gathered 719 words on 007-2.png\n",
      "Started to generate pagexml for 007-2.png\n",
      "book2_words_lines_page_xmls/007-2.xml\n",
      "008-1.png\n",
      "book2_hadara_xmls/008-1.xml\n",
      "Gathered 701 words on 008-1.png\n",
      "Started to generate pagexml for 008-1.png\n",
      "book2_words_lines_page_xmls/008-1.xml\n",
      "003-1.png\n",
      "book2_hadara_xmls/003-1.xml\n",
      "Gathered 343 words on 003-1.png\n",
      "Started to generate pagexml for 003-1.png\n",
      "book2_words_lines_page_xmls/003-1.xml\n",
      "All the pages have been processed.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(words_lines_page_xmls_dir):\n",
    "    shutil.rmtree(words_lines_page_xmls_dir)\n",
    "os.mkdir(words_lines_page_xmls_dir)\n",
    "total_sorted_word_labels = []\n",
    "total_line_labels = []\n",
    "c=0\n",
    "for image_name in os.listdir(color_images_dir):\n",
    "    print(image_name)\n",
    "    image_root_name = image_name[:-4]\n",
    "    hadara_xml_path = hadara_xmls_dir + image_root_name + '.xml'\n",
    "    print(hadara_xml_path)\n",
    "      \n",
    "    word_bboxes, word_labels = word_bboxes_and_labels_from_hadara_xml(hadara_xml_path, image_root_name)\n",
    "    sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels = lines_from_words(word_bboxes, word_labels)\n",
    "\n",
    "    print ('Started to generate pagexml for '+ image_name)\n",
    "    image_path = color_images_dir + image_name\n",
    "    generate_pagexml(words_lines_page_xmls_dir, image_path, sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels)\n",
    "\n",
    "print ('All the pages have been processed.')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
